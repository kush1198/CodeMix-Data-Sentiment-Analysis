{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled7.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dD5wE98QRydh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"817601d0-9b30-493f-d0c6-86d551b19050","executionInfo":{"status":"ok","timestamp":1566452965292,"user_tz":-330,"elapsed":4058,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.engine.topology import Layer\n","from keras import initializers as initializers, regularizers, constraints\n","from keras.callbacks import Callback\n","from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\n","from keras import backend as K\n","from keras.models import Model\n","\n","\n","from sklearn.metrics import roc_auc_score"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qJeo-CtNd7dI","colab_type":"code","outputId":"1ef6f857-5a3d-4b81-ac53-f3c922daebc5","executionInfo":{"status":"ok","timestamp":1566452965316,"user_tz":-330,"elapsed":739,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Colab Notebooks/HAN"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/HAN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fGRBLv4xIiRS","colab_type":"code","colab":{}},"source":["# %load char-rnn.py\n","import numpy as np\n","import h5py\n","import pickle\n","from copy import deepcopy\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from keras import backend as K\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, GRU\n","from keras.layers.convolutional import Convolution1D, MaxPooling1D\n","from keras.layers import Conv1D\n","import tensorflow as tf\n","\n","from keras.utils import np_utils\n","from MyNormalizer import token\n","\n","################# GLOBAL VARIABLES #####################\n","#Filenames\n","#TODO: Add to coding conventions that directories are to always end with '/'\n","Masterdir = '/Download/Sub-word-LSTM/Sub-word-LSTM-master'\n","Datadir = 'Data/'\n","Modeldir = 'Models/'\n","Featuredir = 'Features/'\n","inputdatasetfilename = 'IIITH_Codemixed.txt'\n","exp_details = 'new_experiment'\n","\n","#Data I/O formatting\n","SEPERATOR = '\\t'\n","DATA_COLUMN = 1\n","LABEL_COLUMN = 3\n","LABELS = ['0','1','2'] # 0 -> Negative, 1-> Neutral, 2-> Positive\n","mapping_char2num = {}\n","mapping_num2char = {}\n","MAXLEN = 200\n","\n","#LSTM Model Parameters\n","#Embedding\n","MAX_FEATURES = 0\n","embedding_size = 128\n","# Convolution\n","filter_length = 3\n","nb_filter = 128\n","pool_length = 3\n","# LSTM\n","lstm_output_size = 128\n","# Training\n","batch_size = 128\n","number_of_epochs = 80\n","numclasses = 3\n","test_size = 0.2\n","MAX_WORD_LENGTH = 7\n","MAX_WORDS = 20\n","MAX_NB_CHARS = 1000\n","EMBEDDING_DIM = 10\n","VALIDATION_SPLIT = 0.2\n","########################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVNC0CGZIw1j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3fc32ced-dd0a-4331-e9a0-d5fab1d8cc3b","executionInfo":{"status":"ok","timestamp":1566479741432,"user_tz":-330,"elapsed":1135,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["def par(filename,seperator,labelcol,labels):\n","  f=open(filename,'r',encoding='utf-8')\n","  lines=f.read().lower()\n","  lines=lines.lower().split('\\n')[:-1]\n","  sentences = [l.split(seperator) for l in lines]\n","  sentences=[s[1] for s in sentences]\n","  tokenizer = Tokenizer(num_words=MAX_NB_CHARS, char_level=True)\n","  tokenizer.fit_on_texts(sentences)\n","  data = np.zeros((len(sentences), MAX_WORDS, MAX_WORD_LENGTH), dtype='int32')\n","  for i, words in enumerate(sentences):\n","    for j, word in enumerate(words):\n","        if j < MAX_WORDS:\n","            k = 0\n","            for _, char in enumerate(word):\n","                try:\n","                    if k < MAX_WORD_LENGTH:\n","                        if tokenizer.word_index[char] < MAX_NB_CHARS:\n","                            data[i, j, k] = tokenizer.word_index[char]\n","                            k=k+1\n","                except:\n","                    None\n","  char_index = tokenizer.word_index\n","  lab=[]\n","  for line in lines:\n","    line=line.split(seperator)\n","    if(line[labelcol]==labels[0]):\n","      lab.append(0)\n","    if(line[labelcol]==labels[1]):\n","      lab.append(1)\n","    if(line[labelcol]==labels[2]):\n","      lab.append(2)\n","  lab=np.array(lab)\n","  indices = np.arange(data.shape[0])\n","  np.random.shuffle(indices)\n","  data = data[indices]\n","  lab = lab[indices]\n","  \n","  nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n","  \n","    \n","  x_train = data[:-nb_validation_samples]\n","  y_train = lab[:-nb_validation_samples]\n","  x_val = data[-nb_validation_samples:]\n","  y_val = lab[-nb_validation_samples:]\n","  y_train=tf.keras.utils.to_categorical(y_train)\n","  y_val=tf.keras.utils.to_categorical(y_val)\n","\n","  return (x_train,y_train,x_val,y_val,char_index)\n","par(inputdatasetfilename,SEPERATOR,LABEL_COLUMN,LABELS)\n","  "],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[[11,  0,  0, ...,  0,  0,  0],\n","         [16,  0,  0, ...,  0,  0,  0],\n","         [20,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [23,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[10,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [13,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         [11,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[10,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [13,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         [19,  0,  0, ...,  0,  0,  0],\n","         [16,  0,  0, ...,  0,  0,  0]],\n"," \n","        ...,\n"," \n","        [[14,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 8,  0,  0, ...,  0,  0,  0],\n","         [11,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[18,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [13,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[14,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [15,  0,  0, ...,  0,  0,  0]]], dtype=int32), array([[0., 0., 1.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        ...,\n","        [0., 0., 1.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]], dtype=float32), array([[[12,  0,  0, ...,  0,  0,  0],\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [49,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [18,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         [ 0,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 7,  0,  0, ...,  0,  0,  0],\n","         [18,  0,  0, ...,  0,  0,  0],\n","         [ 8,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[14,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 8,  0,  0, ...,  0,  0,  0],\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [21,  0,  0, ...,  0,  0,  0]],\n"," \n","        ...,\n"," \n","        [[14,  0,  0, ...,  0,  0,  0],\n","         [ 4,  0,  0, ...,  0,  0,  0],\n","         [ 2,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         [10,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 2,  0,  0, ...,  0,  0,  0],\n","         [14,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [ 1,  0,  0, ...,  0,  0,  0],\n","         [ 7,  0,  0, ...,  0,  0,  0]],\n"," \n","        [[ 4,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0],\n","         [13,  0,  0, ...,  0,  0,  0],\n","         ...,\n","         [ 3,  0,  0, ...,  0,  0,  0],\n","         [ 6,  0,  0, ...,  0,  0,  0],\n","         [ 5,  0,  0, ...,  0,  0,  0]]], dtype=int32), array([[0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        ...,\n","        [0., 1., 0.],\n","        [0., 1., 0.],\n","        [0., 1., 0.]], dtype=float32), {'\\x08': 82,\n","  ' ': 1,\n","  '!': 38,\n","  '\"': 50,\n","  '#': 42,\n","  '$': 60,\n","  '%': 77,\n","  '&': 58,\n","  \"'\": 34,\n","  '(': 43,\n","  ')': 39,\n","  '*': 35,\n","  '+': 55,\n","  ',': 29,\n","  '-': 40,\n","  '.': 15,\n","  '/': 59,\n","  '0': 30,\n","  '1': 36,\n","  '2': 41,\n","  '3': 28,\n","  '4': 33,\n","  '5': 44,\n","  '6': 46,\n","  '7': 45,\n","  '8': 47,\n","  '9': 48,\n","  ':': 32,\n","  ';': 52,\n","  '<': 31,\n","  '=': 76,\n","  '>': 62,\n","  '?': 27,\n","  '@': 57,\n","  '[': 81,\n","  '\\\\': 75,\n","  '^': 67,\n","  '_': 53,\n","  '`': 74,\n","  'a': 2,\n","  'b': 14,\n","  'c': 22,\n","  'd': 19,\n","  'e': 5,\n","  'f': 23,\n","  'g': 21,\n","  'h': 4,\n","  'i': 3,\n","  'j': 20,\n","  'k': 7,\n","  'l': 13,\n","  'm': 11,\n","  'n': 6,\n","  'o': 8,\n","  'p': 17,\n","  'q': 37,\n","  'r': 9,\n","  's': 10,\n","  't': 12,\n","  'u': 16,\n","  'v': 26,\n","  'w': 24,\n","  'x': 49,\n","  'y': 18,\n","  'z': 25,\n","  '~': 61,\n","  '\\xa0': 66,\n","  '¡': 63,\n","  '¤': 73,\n","  '¦': 56,\n","  '«': 64,\n","  '²': 79,\n","  '¹': 71,\n","  'â': 51,\n","  'ã': 68,\n","  'å': 65,\n","  'ž': 69,\n","  '˜': 72,\n","  '–': 78,\n","  '’': 70,\n","  '”': 80,\n","  '€': 54})"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"j84TbZoUbcB6","colab_type":"code","outputId":"dee9b1ba-5df1-428a-9437-9f5ac6789024","executionInfo":{"status":"ok","timestamp":1566479863581,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["    print('Starting RNN Engine...\\nModel: Char-level LSTM.\\nParsing data files...')\n","    out = par(inputdatasetfilename,SEPERATOR,LABEL_COLUMN,LABELS)\n","    global x_train\n","    global y_train\n","    global x_test\n","    global y_test\n","    x_train = out[0]\n","    y_train = out[1]\n","    x_val=out[2]\n","    y_val=out[3]\n","    char_index=out[4]\n","\n"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Starting RNN Engine...\n","Model: Char-level LSTM.\n","Parsing data files...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JTJo_ABACWWJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":840},"outputId":"b4a58784-a3eb-450e-fc14-39a8ede877d4","executionInfo":{"status":"ok","timestamp":1566479313324,"user_tz":-330,"elapsed":914,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["print(x_train)"],"execution_count":87,"outputs":[{"output_type":"stream","text":["[[[14  0  0 ...  0  0  0]\n","  [ 4  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  ...\n","  [ 1  0  0 ...  0  0  0]\n","  [11  0  0 ...  0  0  0]\n","  [ 8  0  0 ...  0  0  0]]\n","\n"," [[12  0  0 ...  0  0  0]\n","  [16  0  0 ...  0  0  0]\n","  [11  0  0 ...  0  0  0]\n","  ...\n","  [ 4  0  0 ...  0  0  0]\n","  [ 8  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]]\n","\n"," [[23  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  [22  0  0 ...  0  0  0]\n","  ...\n","  [22  0  0 ...  0  0  0]\n","  [ 4  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]]\n","\n"," ...\n","\n"," [[ 4  0  0 ...  0  0  0]\n","  [13  0  0 ...  0  0  0]\n","  [17  0  0 ...  0  0  0]\n","  ...\n","  [25  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]\n","  [14  0  0 ...  0  0  0]]\n","\n"," [[10  0  0 ...  0  0  0]\n","  [ 2  0  0 ...  0  0  0]\n","  [13  0  0 ...  0  0  0]\n","  ...\n","  [20  0  0 ...  0  0  0]\n","  [ 1  0  0 ...  0  0  0]\n","  [20  0  0 ...  0  0  0]]\n","\n"," [[12  0  0 ...  0  0  0]\n","  [16  0  0 ...  0  0  0]\n","  [11  0  0 ...  0  0  0]\n","  ...\n","  [ 2  0  0 ...  0  0  0]\n","  [17  0  0 ...  0  0  0]\n","  [ 6  0  0 ...  0  0  0]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qBXOhBnM4wuF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2bd6a71a-466b-4820-c722-e7a1e72b6a98","executionInfo":{"status":"ok","timestamp":1566479310306,"user_tz":-330,"elapsed":804,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["x_train.shape"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3104, 20, 7)"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"wBg1QyOMR2tS","colab_type":"code","colab":{}},"source":["def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","    How to use:\n","    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","    The dimensions are inferred based on the output shape of the RNN.\n","    Note: The layer has been tested with Keras 2.0.6\n","    Example:\n","        model.add(LSTM(64, return_sequences=True))\n","        model.add(AttentionWithContext())\n","        # next add a Dense layer (for classification/regression) or whatever...\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOaH4X4BSO0u","colab_type":"code","colab":{}},"source":["class RocAucEvaluation(Callback):\n","    def __init__(self, validation_data=(), interval=1):\n","        super(Callback, self).__init__()\n","\n","        self.interval = interval\n","        self.X_val, self.y_val = validation_data\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            y_pred = self.model.predict(self.X_val, verbose=0)\n","            score = roc_auc_score(self.y_val, y_pred)\n","            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlNlb12lSRXl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"fa5d890c-f3c1-43eb-ab84-2752536faf7d","executionInfo":{"status":"ok","timestamp":1566485615496,"user_tz":-330,"elapsed":3241,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["embedding_layer = Embedding(len(char_index) + 1,\n","                            EMBEDDING_DIM,\n","                            input_length=MAX_WORD_LENGTH,\n","                            trainable=True)\n","\n","char_input = Input(shape=(MAX_WORD_LENGTH,), dtype='int32')\n","char_sequences = embedding_layer(char_input)\n","char_conv=Convolution1D(nb_filter=nb_filter,\n","\t\t\t\t\t\t\tfilter_length=filter_length,\n","\t\t\t\t\t\t\tborder_mode='valid',\n","\t\t\t\t\t\t\tactivation='relu',\n","\t\t\t\t\t\t\tsubsample_length=1)(char_sequences)\n","char_maxpool=MaxPooling1D(pool_length=pool_length)(char_conv)\n","char_lstm = Bidirectional(LSTM(100, return_sequences=True))(char_maxpool)\n","char_dense = TimeDistributed(Dense(200))(char_lstm)\n","char_att = AttentionWithContext()(char_dense)\n","charEncoder = Model(char_input, char_att)\n","\n","words_input = Input(shape=(MAX_WORDS, MAX_WORD_LENGTH), dtype='int32')\n","words_encoder = TimeDistributed(charEncoder)(words_input)\n","words_lstm = Bidirectional(LSTM(100, return_sequences=True))(words_encoder)\n","words_dense = TimeDistributed(Dense(200))(words_lstm)\n","words_att = AttentionWithContext()(words_dense)\n","preds = Dense(3, activation='softmax')(words_att)\n","model = Model(words_input, preds)\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adamax',\n","              metrics=['acc'])"],"execution_count":110,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=3, strides=1, padding=\"valid\")`\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n","  del sys.path[0]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2xrpLqaOST2H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"04a035b9-a3e5-4d73-a61c-e726198b5173","executionInfo":{"status":"ok","timestamp":1566486777828,"user_tz":-330,"elapsed":1126088,"user":{"displayName":"Kushagra Bhatia","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC8m2Hqe_J_VckJ1PlnRCIhfLS2zsKUH5E0SzgRfA=s64","userId":"12476490699397159076"}}},"source":["RocAuc = RocAucEvaluation(validation_data=(x_val, y_val), interval=1)\n","model.fit(x_train, y_train, validation_data=(x_val, y_val),\n","          epochs=100, batch_size=64)"],"execution_count":112,"outputs":[{"output_type":"stream","text":["Train on 3104 samples, validate on 775 samples\n","Epoch 1/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9942 - acc: 0.5045 - val_loss: 1.0010 - val_acc: 0.5045\n","Epoch 2/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9930 - acc: 0.5045 - val_loss: 1.0014 - val_acc: 0.5045\n","Epoch 3/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9930 - acc: 0.5045 - val_loss: 0.9987 - val_acc: 0.5045\n","Epoch 4/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9866 - acc: 0.5045 - val_loss: 0.9878 - val_acc: 0.5045\n","Epoch 5/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9757 - acc: 0.5074 - val_loss: 0.9765 - val_acc: 0.5097\n","Epoch 6/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9630 - acc: 0.5151 - val_loss: 0.9680 - val_acc: 0.5252\n","Epoch 7/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9553 - acc: 0.5338 - val_loss: 0.9671 - val_acc: 0.5484\n","Epoch 8/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9464 - acc: 0.5341 - val_loss: 0.9743 - val_acc: 0.5110\n","Epoch 9/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9385 - acc: 0.5329 - val_loss: 0.9651 - val_acc: 0.5394\n","Epoch 10/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9337 - acc: 0.5457 - val_loss: 0.9654 - val_acc: 0.5432\n","Epoch 11/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9373 - acc: 0.5370 - val_loss: 0.9586 - val_acc: 0.5432\n","Epoch 12/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9305 - acc: 0.5432 - val_loss: 0.9864 - val_acc: 0.5329\n","Epoch 13/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9286 - acc: 0.5528 - val_loss: 0.9518 - val_acc: 0.5600\n","Epoch 14/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9279 - acc: 0.5564 - val_loss: 0.9624 - val_acc: 0.5419\n","Epoch 15/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9277 - acc: 0.5454 - val_loss: 0.9738 - val_acc: 0.5432\n","Epoch 16/100\n","3104/3104 [==============================] - 12s 4ms/step - loss: 0.9187 - acc: 0.5622 - val_loss: 0.9475 - val_acc: 0.5510\n","Epoch 17/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9173 - acc: 0.5660 - val_loss: 0.9544 - val_acc: 0.5600\n","Epoch 18/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9171 - acc: 0.5596 - val_loss: 0.9507 - val_acc: 0.5574\n","Epoch 19/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9141 - acc: 0.5683 - val_loss: 0.9432 - val_acc: 0.5548\n","Epoch 20/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9101 - acc: 0.5596 - val_loss: 0.9413 - val_acc: 0.5523\n","Epoch 21/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9122 - acc: 0.5689 - val_loss: 0.9432 - val_acc: 0.5561\n","Epoch 22/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.9062 - acc: 0.5641 - val_loss: 0.9461 - val_acc: 0.5535\n","Epoch 23/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8989 - acc: 0.5660 - val_loss: 0.9601 - val_acc: 0.5471\n","Epoch 24/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8965 - acc: 0.5689 - val_loss: 0.9376 - val_acc: 0.5587\n","Epoch 25/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8907 - acc: 0.5767 - val_loss: 0.9590 - val_acc: 0.5419\n","Epoch 26/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8897 - acc: 0.5754 - val_loss: 0.9516 - val_acc: 0.5458\n","Epoch 27/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8937 - acc: 0.5664 - val_loss: 0.9614 - val_acc: 0.5381\n","Epoch 28/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8893 - acc: 0.5696 - val_loss: 0.9330 - val_acc: 0.5652\n","Epoch 29/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8820 - acc: 0.5686 - val_loss: 0.9243 - val_acc: 0.5639\n","Epoch 30/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8796 - acc: 0.5773 - val_loss: 0.9251 - val_acc: 0.5574\n","Epoch 31/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8755 - acc: 0.5796 - val_loss: 0.9593 - val_acc: 0.5729\n","Epoch 32/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8763 - acc: 0.5757 - val_loss: 0.9636 - val_acc: 0.5652\n","Epoch 33/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8759 - acc: 0.5738 - val_loss: 0.9344 - val_acc: 0.5587\n","Epoch 34/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8683 - acc: 0.5854 - val_loss: 0.9365 - val_acc: 0.5652\n","Epoch 35/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8721 - acc: 0.5793 - val_loss: 0.9483 - val_acc: 0.5639\n","Epoch 36/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8625 - acc: 0.5799 - val_loss: 0.9485 - val_acc: 0.5626\n","Epoch 37/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8607 - acc: 0.5847 - val_loss: 0.9464 - val_acc: 0.5729\n","Epoch 38/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8612 - acc: 0.5860 - val_loss: 0.9545 - val_acc: 0.5458\n","Epoch 39/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8525 - acc: 0.5873 - val_loss: 0.9403 - val_acc: 0.5497\n","Epoch 40/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8543 - acc: 0.5944 - val_loss: 0.9579 - val_acc: 0.5690\n","Epoch 41/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8541 - acc: 0.5912 - val_loss: 0.9509 - val_acc: 0.5639\n","Epoch 42/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8544 - acc: 0.5873 - val_loss: 0.9381 - val_acc: 0.5652\n","Epoch 43/100\n","3104/3104 [==============================] - 12s 4ms/step - loss: 0.8503 - acc: 0.6018 - val_loss: 0.9575 - val_acc: 0.5355\n","Epoch 44/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8565 - acc: 0.5909 - val_loss: 0.9381 - val_acc: 0.5497\n","Epoch 45/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8466 - acc: 0.5870 - val_loss: 0.9476 - val_acc: 0.5690\n","Epoch 46/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8356 - acc: 0.6044 - val_loss: 0.9389 - val_acc: 0.5742\n","Epoch 47/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8322 - acc: 0.6044 - val_loss: 0.9589 - val_acc: 0.5587\n","Epoch 48/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8280 - acc: 0.6076 - val_loss: 0.9555 - val_acc: 0.5626\n","Epoch 49/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8249 - acc: 0.6121 - val_loss: 0.9555 - val_acc: 0.5690\n","Epoch 50/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8252 - acc: 0.6066 - val_loss: 0.9475 - val_acc: 0.5484\n","Epoch 51/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8191 - acc: 0.6166 - val_loss: 0.9574 - val_acc: 0.5406\n","Epoch 52/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8124 - acc: 0.6192 - val_loss: 0.9339 - val_acc: 0.5600\n","Epoch 53/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8111 - acc: 0.6108 - val_loss: 0.9557 - val_acc: 0.5677\n","Epoch 54/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8073 - acc: 0.6211 - val_loss: 0.9611 - val_acc: 0.5406\n","Epoch 55/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.8029 - acc: 0.6269 - val_loss: 0.9490 - val_acc: 0.5458\n","Epoch 56/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7995 - acc: 0.6276 - val_loss: 0.9477 - val_acc: 0.5484\n","Epoch 57/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7977 - acc: 0.6298 - val_loss: 0.9686 - val_acc: 0.5535\n","Epoch 58/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7854 - acc: 0.6356 - val_loss: 0.9643 - val_acc: 0.5561\n","Epoch 59/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7866 - acc: 0.6369 - val_loss: 0.9864 - val_acc: 0.5368\n","Epoch 60/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7828 - acc: 0.6302 - val_loss: 0.9759 - val_acc: 0.5613\n","Epoch 61/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7925 - acc: 0.6327 - val_loss: 0.9687 - val_acc: 0.5406\n","Epoch 62/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7736 - acc: 0.6427 - val_loss: 0.9853 - val_acc: 0.5484\n","Epoch 63/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7674 - acc: 0.6392 - val_loss: 0.9840 - val_acc: 0.5458\n","Epoch 64/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7454 - acc: 0.6537 - val_loss: 1.0086 - val_acc: 0.5445\n","Epoch 65/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7533 - acc: 0.6540 - val_loss: 1.0096 - val_acc: 0.5265\n","Epoch 66/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7524 - acc: 0.6521 - val_loss: 1.0351 - val_acc: 0.5445\n","Epoch 67/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7307 - acc: 0.6637 - val_loss: 1.0218 - val_acc: 0.5277\n","Epoch 68/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7307 - acc: 0.6633 - val_loss: 1.0362 - val_acc: 0.5303\n","Epoch 69/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7344 - acc: 0.6688 - val_loss: 1.0217 - val_acc: 0.5523\n","Epoch 70/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6972 - acc: 0.6846 - val_loss: 1.0714 - val_acc: 0.5174\n","Epoch 71/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6943 - acc: 0.6859 - val_loss: 1.1028 - val_acc: 0.4968\n","Epoch 72/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.7070 - acc: 0.6769 - val_loss: 1.0376 - val_acc: 0.5265\n","Epoch 73/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6823 - acc: 0.6901 - val_loss: 1.0659 - val_acc: 0.5303\n","Epoch 74/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6819 - acc: 0.6939 - val_loss: 1.0809 - val_acc: 0.5277\n","Epoch 75/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6610 - acc: 0.6930 - val_loss: 1.0877 - val_acc: 0.5161\n","Epoch 76/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6528 - acc: 0.7078 - val_loss: 1.1151 - val_acc: 0.5161\n","Epoch 77/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6417 - acc: 0.7155 - val_loss: 1.1157 - val_acc: 0.5316\n","Epoch 78/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6316 - acc: 0.7191 - val_loss: 1.1391 - val_acc: 0.5265\n","Epoch 79/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6174 - acc: 0.7236 - val_loss: 1.1530 - val_acc: 0.5200\n","Epoch 80/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.6085 - acc: 0.7278 - val_loss: 1.1857 - val_acc: 0.5187\n","Epoch 81/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5905 - acc: 0.7423 - val_loss: 1.2161 - val_acc: 0.5123\n","Epoch 82/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5844 - acc: 0.7413 - val_loss: 1.2221 - val_acc: 0.4916\n","Epoch 83/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5637 - acc: 0.7481 - val_loss: 1.2730 - val_acc: 0.5058\n","Epoch 84/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5597 - acc: 0.7590 - val_loss: 1.2382 - val_acc: 0.5368\n","Epoch 85/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5391 - acc: 0.7651 - val_loss: 1.2296 - val_acc: 0.5187\n","Epoch 86/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5299 - acc: 0.7700 - val_loss: 1.3807 - val_acc: 0.4903\n","Epoch 87/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.5256 - acc: 0.7738 - val_loss: 1.3087 - val_acc: 0.5303\n","Epoch 88/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4988 - acc: 0.7832 - val_loss: 1.3477 - val_acc: 0.5368\n","Epoch 89/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4832 - acc: 0.7983 - val_loss: 1.3611 - val_acc: 0.5110\n","Epoch 90/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4735 - acc: 0.7935 - val_loss: 1.4055 - val_acc: 0.5548\n","Epoch 91/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4659 - acc: 0.8054 - val_loss: 1.4220 - val_acc: 0.5329\n","Epoch 92/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4470 - acc: 0.8135 - val_loss: 1.4731 - val_acc: 0.5381\n","Epoch 93/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4336 - acc: 0.8218 - val_loss: 1.4733 - val_acc: 0.5174\n","Epoch 94/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4021 - acc: 0.8370 - val_loss: 1.5345 - val_acc: 0.5471\n","Epoch 95/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.4093 - acc: 0.8276 - val_loss: 1.5548 - val_acc: 0.5174\n","Epoch 96/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.3798 - acc: 0.8428 - val_loss: 1.6186 - val_acc: 0.5239\n","Epoch 97/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.3859 - acc: 0.8460 - val_loss: 1.5994 - val_acc: 0.5303\n","Epoch 98/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.3683 - acc: 0.8547 - val_loss: 1.6523 - val_acc: 0.5548\n","Epoch 99/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.3400 - acc: 0.8653 - val_loss: 1.6683 - val_acc: 0.5161\n","Epoch 100/100\n","3104/3104 [==============================] - 11s 4ms/step - loss: 0.3287 - acc: 0.8737 - val_loss: 1.8187 - val_acc: 0.5239\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0ae06608d0>"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"RRCivn51ekVN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}